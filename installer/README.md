# WFR DAQ System - Installation Guide

## ğŸš€ Quick Start

**With Slack Integration:**
```bash
cd installer
./scripts/start-daq-system-no-slack.sh
```

### Step 2: Manual Installation Steps

If you prefer manual control or troubleshooting:

**Full Installation:**
```bash
docker-compose up -d influxdb2
sleep 15
./scripts/extract-token-docker.sh
docker-compose up -d
```

**Minimal Installation (no Slack):**
```bash
docker-compose -f docker-compose.no-slack.yml up -d
```

**Without Slack (Minimal Setup):**
```bash
cd installer
./scripts/start-daq-system-no-slack.sh
```
sleep 15
./scripts/extract-token-docker.sh
docker-compose -f docker-compose.no-slack.yml up -d
```GitHub/DAQServerHelpers/installer
./scripts/start-daq-system.sh
```

**Without Slack (Minimal Setup):**
```bash
cd installer
./scripts/start-daq-system-no-slack.sh
```

## ğŸ“‹ System Overview

The WFR DAQ (Data Acquisition) system is a containerized solution for collecting, storing, and visualizing Formula Racing car telemetry data. This installer sets up a complete data pipeline including:

- **InfluxDB v2**: Time-series database for telemetry storage
- **Grafana**: Real-time dashboard and visualization platform  
- **CAN Data Receiver**: Processes CAN bus frames from the race car
- **Slack Bot**: Provides team notifications and data analysis
- **Lap Timing System**: Tracks and analyzes lap performance
- **Frontend Application**: Web interface for system management

## ğŸ—ï¸ Installation Process

### Option A: Full Installation (with Slack)
```bash
./scripts/start-daq-system.sh
```

### Option B: Minimal Installation (no Slack)
```bash
./scripts/start-daq-system-no-slack.sh
```

Both options provide the same core functionality, but the minimal installation excludes:
- Slack bot container
- Slack startup notifications
- Slack-related dependencies

**What happens during startup:**

1. **InfluxDB Initialization** (30 seconds)
   - Starts InfluxDB container with persistent storage
   - Waits for database to become ready
   - Configures organization "WFR" and bucket "ourCar"

2. **Token Extraction** (Automatic)
   - Uses Docker-based CLI to extract all-access token
   - Creates `.env` file with `INFLUXDB_TOKEN`
   - Falls back to Python/Bash API methods if needed

3. **Service Deployment** (30 seconds)
   - Starts all services in dependency order
   - Establishes `datalink` network for inter-container communication
   - Applies resource limits and restart policies

4. **Startup Data Loading** (Automatic)
   - Loads any CSV files from `startup-data/` directory
   - Uses DBC file to decode CAN messages
   - Streams historical telemetry data to InfluxDB
   - Provides real-time progress feedback

5. **Configuration Provisioning** (Automatic)
   - Grafana auto-configures InfluxDB datasource
   - Loads default dashboards from `grafana/dashboards/`
   - Sets up admin user: `admin` / `turbo-charged-plotting-machine`

6. **Health Verification & Notifications** (15 seconds)
   - Tests all service endpoints
   - Verifies Grafana â†” InfluxDB connectivity
   - Reports system status and access URLs
   - Sends comprehensive status to Slack (if configured)

### Step 2: Access Services

After successful installation, access these URLs:

- **ğŸ“Š Grafana Dashboard**: http://localhost:8087
- **ğŸ—„ï¸ InfluxDB Interface**: http://localhost:8086  
- **ğŸ–¥ï¸ Frontend Application**: http://localhost:8060
- **ğŸ“¡ CAN Data Receiver**: http://localhost:8085
- **ğŸ“ˆ Lap Timing System**: http://localhost:8050

## ğŸ”§ Manual Installation Steps

If you prefer manual control or troubleshooting:

### 1. Start Core Database
```bash
docker-compose up -d influxdb2
sleep 15  # Wait for initialization
```

### 2. Extract Authentication Token
```bash
./scripts/extract-token-docker.sh
```

### 3. Start All Services
```bash
docker-compose up -d
```

### 4. Verify System Health
```bash
docker ps  # Check container status
docker logs grafana  # Check Grafana logs
curl http://localhost:8087/api/health  # Test Grafana
```

## ğŸ“ Project Structure

```
installer/
â”œâ”€â”€ docker-compose.yml           # Container orchestration
â”œâ”€â”€ .env                        # Auto-generated secrets
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ TOKEN_EXTRACTION_README.md  # Token automation docs
â”‚
â”œâ”€â”€ scripts/                    # Automation scripts
â”‚   â”œâ”€â”€ start-daq-system.sh    # Main installer
â”‚   â”œâ”€â”€ extract-token-docker.sh # Docker-based token extraction  
â”‚   â”œâ”€â”€ extract-influx-token.py # Python API extraction
â”‚   â””â”€â”€ extract-influx-token.sh # Bash API extraction
â”‚
â”œâ”€â”€ startup-data/              # Historical telemetry data
â”‚   â”œâ”€â”€ *.csv                  # CAN data files (auto-loaded)
â”‚   â”œâ”€â”€ WFR25.dbc              # CAN database file
â”‚   â””â”€â”€ helper.py              # Data processing utilities
â”‚
â”œâ”€â”€ startup-data-loader/       # Data ingestion container
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ load_data.py           # CSV to InfluxDB streamer
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ grafana/                    # Grafana configuration
â”‚   â”œâ”€â”€ provisioning/
â”‚   â”‚   â”œâ”€â”€ datasources/        # Auto InfluxDB connection
â”‚   â”‚   â””â”€â”€ dashboards/         # Dashboard provider config
â”‚   â”œâ”€â”€ dashboards/             # JSON dashboard files
â”‚   â””â”€â”€ README.md               # Dashboard import guide
â”‚
â”œâ”€â”€ car-to-influx/             # CAN data processor
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ listener.py
â”‚   â”œâ”€â”€ WFR25-f772b40.dbc      # CAN database file
â”‚   â””â”€â”€ templates/
â”‚
â”œâ”€â”€ slackbot/                  # Team notifications
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ slack_bot.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ lappy/                     # Lap timing analysis
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ lap.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ frontend-build/            # Web interface
    â”œâ”€â”€ index.html
    â””â”€â”€ assets/
```

## ğŸ”’ Security & Credentials

### Default Accounts
- **Grafana**: `admin` / `turbo-charged-plotting-machine`
- **InfluxDB**: `admin` / `turbo-charged-falcon-machine`
- **Organization**: `WFR`
- **Bucket**: `ourCar`

### Token Management
- InfluxDB tokens are automatically extracted and rotated
- Slack tokens are configured in `docker-compose.yml`
- All secrets stored in `.env` file (git-ignored)
- Slack webhook URL can be set via `SLACK_WEBHOOK_URL` environment variable

## ï¿½ Slack Integration

### Automatic Startup Notifications
The system automatically sends a comprehensive status report to Slack after startup, including:
- Service status for all containers
- Connectivity test results  
- Service URLs and access information
- Data loading completion status

### Configuration
```bash
# Add to .env file:
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL
```

### Manual Slack Bot Setup
```bash
# Edit docker-compose.yml:
environment:
  SLACK_BOT_TOKEN: "xoxb-your-bot-token-here"
  SLACK_APP_TOKEN: "xapp-your-app-token-here"

# Restart slackbot service:
docker-compose restart slackbot
```

## ï¿½ğŸ› Troubleshooting

### Common Issues

**Services won't start:**
```bash
docker-compose logs SERVICE_NAME
docker system prune  # Clean up resources
```

**Token extraction fails:**
```bash
# Manual token creation
open http://localhost:8086
# Login â†’ Data â†’ API Tokens â†’ Generate API Token
# Copy token to .env file
```

**Grafana can't connect to InfluxDB:**
```bash
docker logs grafana
# Check datasource configuration
# Verify token in .env file
```

**Port conflicts:**
```bash
lsof -i :8087  # Check what's using Grafana port
# Modify ports in docker-compose.yml if needed
```

## ğŸ“ˆ Data Flow

1. **Historical Data Loading** â†’ CSV files in `startup-data/` automatically loaded on first start
2. **Race Car** â†’ CAN Bus frames
3. **CAN Receiver** (port 8085) â†’ Processes frames using DBC file
4. **InfluxDB** (port 8086) â†’ Stores time-series data
5. **Grafana** (port 8087) â†’ Visualizes real-time telemetry
6. **Slack Bot** â†’ Sends race notifications
7. **Frontend** (port 8060) â†’ System management interface

## ğŸ”„ Maintenance

### Daily Operations
```bash
# View system status
docker ps

# Monitor logs  
docker-compose logs -f

# Restart specific service
docker-compose restart SERVICE_NAME

# Update containers
docker-compose pull && docker-compose up -d
```

### Data Backup
```bash
# Backup InfluxDB data
docker exec influxdb2 influx backup /backup
docker cp influxdb2:/backup ./influxdb-backup-$(date +%Y%m%d)

# Backup Grafana dashboards
cp -r grafana/dashboards ./grafana-backup-$(date +%Y%m%d)
```

## ğŸ“ Support

For issues or questions:
- Check logs: `docker logs CONTAINER_NAME`
- Review documentation in `TOKEN_EXTRACTION_README.md`
- Contact DAQ Team Lead
- Review Western Formula Racing DAQ documentation
